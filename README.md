# post-training-of-LLMs
----2025/10/13----
# 概述
大语言模型的训练有两个阶段：  
 **预训练阶段（pre-training）**：使模型学会预测下一个文字或标注；  
 **后训练阶段（post-training）**：进一步训练模型使得模型具有能够处理任务的能力，比如学会回答问题。
## 后训练阶段
三种后训练方法：  
**监督微调（Supervised Fine-Tuning）SFT**：通过一些标记好的数据对模型进行训练，使模型模仿输入（提示）与输出（响应）之间的关系。  
**直接偏好优化（direc preference optimization ）DPO**：让模型根据同一提示下的优质响应和劣质响应，使模型偏向优质响应远离劣质响应，帮助提高响应质量，减少不良信息。  
**在线强化学习（online RL）**：用户输入提示，模型做出响应，奖励模型再对回应进行评估，模型再根据奖励分数进行更新。

# 后训练技术介绍 
-----------------------------------
## 后训练（Post-training）
首先对初始化模型进行预训练，根据大量的数据集进行训练，得到一个能够预测下一个词或标注的基础模型。  
以此模型为基础，根据精心筛选的数据学习，使得模型可以升级为指令模型或对话模型。  
在此基础上，对模型进行后训练，使模型能够完成一些特定的任务，形成定制化的模型。  
预训练让模型学会了语言的“语法”和“知识”，而后训练则是为了让模型学会如何“更好地使用”这些知识和语言，以适应特定的任务。
## 预训练（Pre-Training）
预训练是后训练的基础支撑，预训练是在海量、无标注数据中训练出一个模型，使它能够学习一些通用规律和知识。预训练出的模型称作基本模型。  
可以看成去培养一个“人才”，预训练的过程，就是让这个学生去广泛大量的阅读各种书籍、知识，使其能够获取大量通用的知识。  
而下一步的后训练阶段，就是对这个“博学”学生进行专门化的培养，使其成为一名律师或其它专业性的人才。



  
  

